{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23037ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from math import comb\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "# Set up plotting parameters\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Dataset directory\n",
    "dataset_dir = 'dataset'\n",
    "\n",
    "# GLOBAL CONFIGURATION: Set to True for weighted analysis, False for unweighted\n",
    "is_weighted = False\n",
    "file_prefix = 'weighted' if is_weighted else 'unweighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b250e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Power Grid Network Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load all networks and basic statistics\n",
    "networks = {}\n",
    "network_stats = []\n",
    "\n",
    "print(\"Loading networks...\")\n",
    "for i in range(1, 59):\n",
    "    try:\n",
    "        data = loadmat(os.path.join(dataset_dir, f'{i}.mat'))\n",
    "        adj_matrix = data['A']\n",
    "        adj_np = adj_matrix.toarray()\n",
    "        assert (adj_np == adj_np.T).all(), \"Adjacency matrix is not symmetric\"\n",
    "        assert np.diag(adj_np).sum() == 0, \"Adjacency matrix has self-loops\"\n",
    "        \n",
    "        # Convert sparse matrix to NetworkX graph\n",
    "        if is_weighted and 'W' in data:\n",
    "            # Use distance matrix as weights\n",
    "            weight_matrix = data['W']\n",
    "            G = nx.from_scipy_sparse_array(weight_matrix)\n",
    "            print(f\"Network {i}: Using weighted graph with distance matrix\")\n",
    "        else:\n",
    "            # Use unweighted adjacency matrix\n",
    "            G = nx.from_scipy_sparse_array(adj_matrix)\n",
    "            if is_weighted:\n",
    "                print(f\"Network {i}: Warning - 'W' matrix not found, using unweighted\")\n",
    "        \n",
    "        # Remove self-loops and ensure undirected\n",
    "        G.remove_edges_from(nx.selfloop_edges(G))\n",
    "        G = G.to_undirected()\n",
    "        \n",
    "        networks[i] = G\n",
    "        \n",
    "        # Collect basic statistics\n",
    "        stats = {\n",
    "            'network_id': i,\n",
    "            'nodes': G.number_of_nodes(),\n",
    "            'edges': G.number_of_edges(),\n",
    "            'density': nx.density(G),\n",
    "            'is_connected': nx.is_connected(G)\n",
    "        }\n",
    "        network_stats.append(stats)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Loaded network {i}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading network {i}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(networks)} networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CYCLE ENUMERATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def enumerate_simple_cycles_undirected(G: nx.Graph, max_len: int = 12) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Count simple cycles by length in an undirected, simple graph up to max_len.\n",
    "    Uses a bounded DFS with canonical node ordering to avoid duplicates.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX undirected graph\n",
    "        max_len: Maximum cycle length to search for\n",
    "    \n",
    "    Returns:\n",
    "        dict {cycle_length: count}\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    \n",
    "    # Use integer labels to reduce overhead\n",
    "    mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    H = nx.relabel_nodes(G, mapping, copy=True)\n",
    "    neighbors = {u: list(H.neighbors(u)) for u in H.nodes()}\n",
    "\n",
    "    def dfs(start: int, current: int, parent: int, visited: Set[int], path: List[int]):\n",
    "        \"\"\"\n",
    "        DFS to find cycles starting from 'start' node.\n",
    "        \n",
    "        Args:\n",
    "            start: the starting node (smallest in the cycle for canonical form)\n",
    "            current: current node in DFS\n",
    "            parent: previous node (to avoid immediate backtracking)\n",
    "            visited: set of visited nodes in current path\n",
    "            path: list maintaining the current path\n",
    "        \"\"\"\n",
    "        if len(path) > max_len:\n",
    "            return\n",
    "            \n",
    "        for w in neighbors[current]:\n",
    "            # Canonical ordering: only consider nodes >= start\n",
    "            if w < start:\n",
    "                continue\n",
    "                \n",
    "            # Don't backtrack to parent (avoids length-2 cycles)\n",
    "            if w == parent:\n",
    "                continue\n",
    "                \n",
    "            # Found a cycle back to start (length >= 3)\n",
    "            if w == start and len(path) >= 3:\n",
    "                counts[len(path)] += 1\n",
    "                continue\n",
    "                \n",
    "            # Continue DFS if not visited and within length limit\n",
    "            if w not in visited and len(path) < max_len:\n",
    "                visited.add(w)\n",
    "                path.append(w)\n",
    "                dfs(start, w, current, visited, path)\n",
    "                path.pop()\n",
    "                visited.remove(w)\n",
    "\n",
    "    # Start DFS from each node\n",
    "    nodes_sorted = sorted(H.nodes())\n",
    "    for s in nodes_sorted:\n",
    "        visited = {s}\n",
    "        dfs(s, s, -1, visited, [s])\n",
    "\n",
    "    # Each cycle is counted twice (clockwise and counterclockwise)\n",
    "    # Divide by 2 to get actual count\n",
    "    for length in counts:\n",
    "        counts[length] //= 2\n",
    "    \n",
    "    return dict(counts)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ENSEMBLE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def cycles_ensemble(networks_dict: Dict[int, nx.Graph], max_r: int = 12, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Aggregate cycle statistics across multiple networks.\n",
    "    \n",
    "    Args:\n",
    "        networks_dict: Dictionary mapping network_id to NetworkX graph\n",
    "        max_r: Maximum cycle length to search\n",
    "        verbose: Print progress information\n",
    "    \n",
    "    Returns:\n",
    "        numpy array with columns: [normalized_r, count, network_id, r]\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for net_id in range(1, 11):\n",
    "        if net_id not in networks_dict:\n",
    "            print(f\"Warning: Network {net_id} not found in dictionary\")\n",
    "            continue\n",
    "            \n",
    "        G = networks_dict[net_id]\n",
    "        n = G.number_of_nodes()\n",
    "        \n",
    "        if n < 3:\n",
    "            print(f\"Network {net_id}: Too few nodes ({n}) for cycles\")\n",
    "            continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Processing network {net_id}: {n} nodes, {G.number_of_edges()} edges...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        hist = enumerate_simple_cycles_undirected(G, max_len=max_r)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        if verbose:\n",
    "            total_cycles = sum(hist.values())\n",
    "            print(f\"  Found {total_cycles} cycles in {elapsed:.2f}s\")\n",
    "            if hist:\n",
    "                print(f\"  Cycle lengths: {sorted(hist.keys())}\")\n",
    "        \n",
    "        for r, c in hist.items():\n",
    "            rows.append((r / n, c, net_id, r))\n",
    "    \n",
    "    return np.array(rows, dtype=float) if rows else np.array([])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Q1: Cycle Analysis for Power Grid Networks\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Run ensemble analysis\n",
    "print(\"Analyzing cycles in first 10 networks...\\n\")\n",
    "rows = cycles_ensemble(networks, max_r=15, verbose=True)\n",
    "\n",
    "if rows.size == 0:\n",
    "    print(\"\\nERROR: No cycles found! Check your networks.\")\n",
    "else:\n",
    "    print(f\"\\nTotal data points collected: {len(rows)}\")\n",
    "    print(f\"Normalized r range: [{rows[:, 0].min():.4f}, {rows[:, 0].max():.4f}]\")\n",
    "    print(f\"Cycle count range: [{rows[:, 1].min():.0f}, {rows[:, 1].max():.0f}]\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FITTING\n",
    "    # ========================================================================\n",
    "    \n",
    "    x = rows[:, 0]  # normalized r\n",
    "    y = rows[:, 1]  # counts\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Fitting exponential model: y = a * exp(b * x)\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Fit exponential: log(y) = log(a) + b*x\n",
    "    # Filter out zeros for log transform\n",
    "    mask = y > 0\n",
    "    x_fit = x[mask]\n",
    "    y_fit = y[mask]\n",
    "    \n",
    "    coeff = np.polyfit(x_fit, np.log(y_fit), 1)  # [b, log(a)]\n",
    "    b, log_a = coeff\n",
    "    a = np.exp(log_a)\n",
    "    \n",
    "    print(f\"\\nFitted parameters:\")\n",
    "    print(f\"  a = {a:.2e}\")\n",
    "    print(f\"  b = {b:.4f}\")\n",
    "    print(f\"\\nModel: y = {a:.2e} * exp({b:.4f} * x)\")\n",
    "    \n",
    "    # Also try polynomial fit for comparison\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Fitting polynomial model (degree 3) for comparison\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    poly_coeff = np.polyfit(x, y, deg=3)\n",
    "    poly = np.poly1d(poly_coeff)\n",
    "    print(f\"\\nPolynomial coefficients (highest to lowest degree):\")\n",
    "    for i, c in enumerate(poly_coeff):\n",
    "        print(f\"  x^{3-i}: {c:.4e}\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    x_grid = np.linspace(0, 1.1 * x.max(), 200)\n",
    "    y_exp = a * np.exp(b * x_grid)\n",
    "    y_poly = poly(x_grid)\n",
    "    \n",
    "    # Calculate R² for both models\n",
    "    from sklearn.metrics import r2_score\n",
    "    y_exp_pred = a * np.exp(b * x)\n",
    "    y_poly_pred = poly(x)\n",
    "    r2_exp = r2_score(y, y_exp_pred)\n",
    "    r2_poly = r2_score(y, y_poly_pred)\n",
    "    \n",
    "    print(f\"\\nModel quality (R² scores):\")\n",
    "    print(f\"  Exponential: {r2_exp:.4f}\")\n",
    "    print(f\"  Polynomial:  {r2_poly:.4f}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # VISUALIZATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Prepare per-network data\n",
    "    per_net = {}\n",
    "    for net_id in range(1, 11):\n",
    "        mask = rows[:, 2] == net_id\n",
    "        if np.any(mask):\n",
    "            Xi = rows[mask][:, 0]\n",
    "            Yi = rows[mask][:, 1]\n",
    "            order = np.argsort(Xi)\n",
    "            per_net[net_id] = (Xi[order], Yi[order])\n",
    "    \n",
    "    # Plot 1: Per-network trends\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Left: Individual networks\n",
    "    ax = axes[0]\n",
    "    for net_id in sorted(per_net.keys()):\n",
    "        Xi, Yi = per_net[net_id]\n",
    "        ax.plot(Xi, Yi, marker='o', linewidth=1.5, markersize=4, alpha=0.7, \n",
    "                label=f'Net {net_id}')\n",
    "    \n",
    "    ax.set_xlabel('Normalized cycle length (r/n)', fontsize=11)\n",
    "    ax.set_ylabel('Number of cycles', fontsize=11)\n",
    "    ax.set_title('Cycle Counts vs Normalized Length\\n(Individual Networks)', fontsize=12, fontweight='bold')\n",
    "    ax.legend(ncol=2, fontsize=9, loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right: Aggregated with fits\n",
    "    ax = axes[1]\n",
    "    ax.scatter(x, y, alpha=0.5, s=30, label='Data', color='blue')\n",
    "    ax.plot(x_grid, y_exp, 'r-', linewidth=2.5, \n",
    "            label=f'Exponential (R²={r2_exp:.3f})')\n",
    "    ax.plot(x_grid, y_poly, 'g--', linewidth=2, \n",
    "            label=f'Polynomial (R²={r2_poly:.3f})')\n",
    "    \n",
    "    ax.set_xlabel('Normalized cycle length (r/n)', fontsize=11)\n",
    "    ax.set_ylabel('Number of cycles', fontsize=11)\n",
    "    ax.set_title('Aggregated Data with Fitted Models', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10, loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    plt.savefig('cycle_count_fits.pdf', dpi=500)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 2: Log-scale visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.scatter(x, y, alpha=0.5, s=30, label='Data', color='blue')\n",
    "    ax.plot(x_grid, y_exp, 'r-', linewidth=2.5, \n",
    "            label=f'Exponential fit: y = {a:.2e} * exp({b:.2f}x)')\n",
    "    \n",
    "    ax.set_xlabel('Normalized cycle length (r/n)', fontsize=12)\n",
    "    ax.set_ylabel('Number of cycles (log scale)', fontsize=12)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title('Cycle Count Distribution (Log Scale)', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    plt.savefig('cycle_count_log_scale.pdf', dpi=500)\n",
    "    plt.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SUMMARY STATISTICS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n✓ Successfully analyzed {len(per_net)} networks\")\n",
    "    print(f\"✓ Total cycles detected: {int(y.sum())}\")\n",
    "    print(f\"✓ Cycle counts generally {'DECREASE' if b < 0 else 'INCREASE'} with normalized length\")\n",
    "    print(f\"✓ Best fit: {'Exponential' if r2_exp > r2_poly else 'Polynomial'} model\")\n",
    "    print(\"\\nConclusion:\")\n",
    "    if b < 0:\n",
    "        print(\"  The number of cycles DECREASES exponentially as normalized length increases.\")\n",
    "        print(\"  This suggests shorter cycles are much more common in power grids,\")\n",
    "        print(\"  which is expected due to their mesh-like structure with local redundancy.\")\n",
    "    else:\n",
    "        print(\"  The number of cycles INCREASES with normalized length (unusual!).\")\n",
    "        print(\"  This may indicate the networks have unique structural properties.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e303e69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1bacf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceve592",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
